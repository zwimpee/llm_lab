{
  "model_name": "meta-llama/Llama-2-7b-chat-hf",
  "model_type": "SequenceClassification",
  "num_labels": 4,
  "label_mapping": {"A": 0, "B": 1, "C": 2, "D": 3},
  "max_length": 4096,
  "pad_to_multiple_of": 8,
  "peft": {
    "lora": {
      "lora_alpha": 16,
      "lora_dropout": 0.05,
      "peft_type": "LORA", 
      "r": 8,
      "target_modules": [
        "q_proj", 
        "v_proj"
      ],
      "task_type": "SEQ_CLS" 
    } 
  },
  "dataset": {
    "name": "cais/mmlu",
    "type": "hf",
    "task_type": "text-classification",
    "splits": {
      "train_split": "auxiliary_train",
      "eval_split": "validation",
      "test_split": "test"
    },
    "args": {
      "subcategories": {
        "abstract_algebra": ["math"],
        "anatomy": ["health"],
        "astronomy": ["physics"],
        "business_ethics": ["business"],
        "clinical_knowledge": ["health"],
        "college_biology": ["biology"],
        "college_chemistry": ["chemistry"],
        "college_computer_science": ["computer science"],
        "college_mathematics": ["math"],
        "college_medicine": ["health"],
        "college_physics": ["physics"],
        "computer_security": ["computer science"],
        "conceptual_physics": ["physics"],
        "econometrics": ["economics"],
        "electrical_engineering": ["engineering"],
        "elementary_mathematics": ["math"],
        "formal_logic": ["philosophy"],
        "global_facts": ["other"],
        "high_school_biology": ["biology"],
        "high_school_chemistry": ["chemistry"],
        "high_school_computer_science": ["computer science"],
        "high_school_european_history": ["history"],
        "high_school_geography": ["geography"],
        "high_school_government_and_politics": ["politics"],
        "high_school_macroeconomics": ["economics"],
        "high_school_mathematics": ["math"],
        "high_school_microeconomics": ["economics"],
        "high_school_physics": ["physics"],
        "high_school_psychology": ["psychology"],
        "high_school_statistics": ["math"],
        "high_school_us_history": ["history"],
        "high_school_world_history": ["history"],
        "human_aging": ["health"],
        "human_sexuality": ["culture"],
        "international_law": ["law"],
        "jurisprudence": ["law"],
        "logical_fallacies": ["philosophy"],
        "machine_learning": ["computer science"],
        "management": ["business"],
        "marketing": ["business"],
        "medical_genetics": ["health"],
        "miscellaneous": ["other"],
        "moral_disputes": ["philosophy"],
        "moral_scenarios": ["philosophy"],
        "nutrition": ["health"],
        "philosophy": ["philosophy"],
        "prehistory": ["history"],
        "professional_accounting": ["other"],
        "professional_law": ["law"],
        "professional_medicine": ["health"],
        "professional_psychology": ["psychology"],
        "public_relations": ["politics"],
        "security_studies": ["politics"],
        "sociology": ["culture"],
        "us_foreign_policy": ["politics"],
        "virology": ["health"],
        "world_religions": ["philosophy"]
      },
    "categories": {
        "STEM": ["physics", "chemistry", "biology", "computer science", "math", "engineering"],
        "humanities": ["history", "philosophy", "law"],
        "social sciences": ["politics", "culture", "economics", "geography", "psychology"],
        "other (business, health, misc.)": ["other", "business", "health"]
      },
      "categor": ["math", "biology", "health", "physics", "computer science"]
    }
  },
  "metric": "accuracy",
  "training_args": {
    "output_dir": "/opt/data/models/meta-llama/Llama-2-7b-chat-hf/mmlu/",
    "overwrite_output_dir": true,
    "do_train": true,
    "do_eval": true,
    "do_predict": false,
    "evaluation_strategy": "steps",
    "per_device_train_batch_size": 1,
    "per_device_eval_batch_size": 1,
    "gradient_accumulation_steps": 1,
    "eval_delay": 0,
    "learning_rate": 5e-5,
    "weight_decay": 0.0,
    "adam_beta1": 0.9,
    "adam_beta2": 0.999,
    "adam_epsilon": 1e-8,
    "max_grad_norm": 1.0,
    "num_train_epochs": 3.0,
    "max_steps": -1,
    "lr_scheduler_type": "linear",
    "lr_scheduler_kwargs": {},
    "warmup_ratio": 0,
    "warmup_steps": 0,
    "log_level": "passive",
    "log_level_replica": "warning",
    "log_on_each_node": true,
    "logging_dir": "/opt/data/logs/",
    "logging_strategy": "steps",
    "logging_first_step": false,
    "logging_steps": 500,
    "logging_nan_inf_filter": true,
    "save_strategy": "steps",
    "save_steps": 500,
    "seed": 42
  }
}